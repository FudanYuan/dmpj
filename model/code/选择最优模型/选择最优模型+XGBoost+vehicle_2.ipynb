{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>charge_start_time</th>\n",
       "      <th>charge_end_time</th>\n",
       "      <th>charge_duration</th>\n",
       "      <th>mileage</th>\n",
       "      <th>delta_mileage</th>\n",
       "      <th>charge_start_soc</th>\n",
       "      <th>charge_end_soc</th>\n",
       "      <th>charge_delta_soc</th>\n",
       "      <th>charge_start_U</th>\n",
       "      <th>charge_end_U</th>\n",
       "      <th>charge_start_I</th>\n",
       "      <th>charge_end_I</th>\n",
       "      <th>charge_max_temp</th>\n",
       "      <th>charge_min_temp</th>\n",
       "      <th>charge_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144.0</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018057e+13</td>\n",
       "      <td>2.018057e+13</td>\n",
       "      <td>16728.694444</td>\n",
       "      <td>69336.175694</td>\n",
       "      <td>154.059722</td>\n",
       "      <td>24.166667</td>\n",
       "      <td>83.354167</td>\n",
       "      <td>59.187500</td>\n",
       "      <td>345.686806</td>\n",
       "      <td>391.150000</td>\n",
       "      <td>-22.375000</td>\n",
       "      <td>-23.509722</td>\n",
       "      <td>34.312500</td>\n",
       "      <td>26.194444</td>\n",
       "      <td>21.994889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.283375e+07</td>\n",
       "      <td>8.337443e+07</td>\n",
       "      <td>15169.845436</td>\n",
       "      <td>7668.957086</td>\n",
       "      <td>89.808357</td>\n",
       "      <td>16.619981</td>\n",
       "      <td>19.354792</td>\n",
       "      <td>23.115692</td>\n",
       "      <td>11.602937</td>\n",
       "      <td>11.483646</td>\n",
       "      <td>18.361949</td>\n",
       "      <td>25.257168</td>\n",
       "      <td>2.834524</td>\n",
       "      <td>2.942996</td>\n",
       "      <td>8.542875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018042e+13</td>\n",
       "      <td>2.018042e+13</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>55676.600000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>329.200000</td>\n",
       "      <td>346.100000</td>\n",
       "      <td>-125.400000</td>\n",
       "      <td>-125.900000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018051e+13</td>\n",
       "      <td>2.018051e+13</td>\n",
       "      <td>2550.750000</td>\n",
       "      <td>63145.625000</td>\n",
       "      <td>111.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>337.200000</td>\n",
       "      <td>391.475000</td>\n",
       "      <td>-33.025000</td>\n",
       "      <td>-32.600000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018060e+13</td>\n",
       "      <td>2.018060e+13</td>\n",
       "      <td>4426.500000</td>\n",
       "      <td>69832.850000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>344.100000</td>\n",
       "      <td>396.500000</td>\n",
       "      <td>-10.400000</td>\n",
       "      <td>-15.450000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018062e+13</td>\n",
       "      <td>2.018062e+13</td>\n",
       "      <td>32006.000000</td>\n",
       "      <td>75400.100000</td>\n",
       "      <td>190.975000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>349.875000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>-8.975000</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>28.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.018071e+13</td>\n",
       "      <td>2.018071e+13</td>\n",
       "      <td>39193.000000</td>\n",
       "      <td>82719.100000</td>\n",
       "      <td>540.900000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>385.900000</td>\n",
       "      <td>397.200000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.431000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vehicle_id  charge_start_time  charge_end_time  charge_duration  \\\n",
       "count       144.0       1.440000e+02     1.440000e+02       144.000000   \n",
       "mean          2.0       2.018057e+13     2.018057e+13     16728.694444   \n",
       "std           0.0       8.283375e+07     8.337443e+07     15169.845436   \n",
       "min           2.0       2.018042e+13     2.018042e+13       270.000000   \n",
       "25%           2.0       2.018051e+13     2.018051e+13      2550.750000   \n",
       "50%           2.0       2.018060e+13     2.018060e+13      4426.500000   \n",
       "75%           2.0       2.018062e+13     2.018062e+13     32006.000000   \n",
       "max           2.0       2.018071e+13     2.018071e+13     39193.000000   \n",
       "\n",
       "            mileage  delta_mileage  charge_start_soc  charge_end_soc  \\\n",
       "count    144.000000     144.000000        144.000000      144.000000   \n",
       "mean   69336.175694     154.059722         24.166667       83.354167   \n",
       "std     7668.957086      89.808357         16.619981       19.354792   \n",
       "min    55676.600000      -0.200000          1.000000       15.000000   \n",
       "25%    63145.625000     111.400000         12.000000       74.750000   \n",
       "50%    69832.850000     147.000000         20.500000       92.000000   \n",
       "75%    75400.100000     190.975000         31.000000       97.000000   \n",
       "max    82719.100000     540.900000         78.000000      100.000000   \n",
       "\n",
       "       charge_delta_soc  charge_start_U  charge_end_U  charge_start_I  \\\n",
       "count        144.000000      144.000000    144.000000      144.000000   \n",
       "mean          59.187500      345.686806    391.150000      -22.375000   \n",
       "std           23.115692       11.602937     11.483646       18.361949   \n",
       "min            2.000000      329.200000    346.100000     -125.400000   \n",
       "25%           46.000000      337.200000    391.475000      -33.025000   \n",
       "50%           63.000000      344.100000    396.500000      -10.400000   \n",
       "75%           76.000000      349.875000    397.000000       -8.975000   \n",
       "max           94.000000      385.900000    397.200000       -0.200000   \n",
       "\n",
       "       charge_end_I  charge_max_temp  charge_min_temp  charge_energy  \n",
       "count    144.000000       144.000000       144.000000     144.000000  \n",
       "mean     -23.509722        34.312500        26.194444      21.994889  \n",
       "std       25.257168         2.834524         2.942996       8.542875  \n",
       "min     -125.900000        25.000000        23.000000       0.704000  \n",
       "25%      -32.600000        33.000000        24.000000      17.913000  \n",
       "50%      -15.450000        35.000000        25.000000      23.520000  \n",
       "75%       -5.100000        37.000000        27.250000      28.001250  \n",
       "max        3.700000        39.000000        35.000000      34.431000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_id = 2\n",
    "data_root = './'  # 改成自己电脑上的路径即可\n",
    "dataset = pd.read_csv(data_root + 'perfect_%d.csv' % vehicle_id)\n",
    "header = dataset.columns.values.tolist()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jeremy/miniconda3/envs/test/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAELCAYAAAA1AlaNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVAjR0FdKqRCioa+UUiHk/wO0YG/uBRBE7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(dataset['charge_energy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['charge_duration',\n",
       "  'mileage',\n",
       "  'delta_mileage',\n",
       "  'charge_start_soc',\n",
       "  'charge_end_soc',\n",
       "  'charge_delta_soc',\n",
       "  'charge_start_U',\n",
       "  'charge_end_U',\n",
       "  'charge_start_I',\n",
       "  'charge_end_I',\n",
       "  'charge_max_temp',\n",
       "  'charge_min_temp'],\n",
       " 'charge_energy')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = header[3:15]\n",
    "label = header[15]\n",
    "features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset[features]\n",
    "y = dataset[label]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择最优模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LinearRegression\n",
      "[ 0.99668695  0.99740428  0.99626232  0.99815366  0.99643967  0.99617352]\n",
      "1 DecisionTreeRegressor\n",
      "[ 0.98525432  0.98665932  0.98647038  0.98556237  0.98542593  0.98441562]\n",
      "2 GradientBoostingRegressor\n",
      "[ 0.98934053  0.99509732  0.99181787  0.99681645  0.99428371  0.99304161]\n",
      "3 MLPRegressor\n",
      "[ 0.98881019  0.99098531  0.98741353  0.99257054  0.99365207  0.97943119]\n",
      "4 AdaBoostRegressor\n",
      "[ 0.98694598  0.99481243  0.98938355  0.99275135  0.99173541  0.98809284]\n",
      "5 BaggingRegressor\n",
      "[ 0.98985175  0.99157585  0.98798935  0.99169669  0.99003484  0.98812077]\n",
      "6 ExtraTreesRegressor\n",
      "[ 0.99206896  0.99513595  0.98763946  0.9951114   0.99318022  0.99225962]\n",
      "7 RandomForestRegressor\n",
      "[ 0.98597875  0.99678612  0.99129713  0.99215748  0.99153959  0.99262305]\n",
      "8 LinearSVR\n",
      "[ 0.99621287  0.99797163  0.99534382  0.99785136  0.99495189  0.99393292]\n",
      "9 NuSVR\n",
      "[ 0.69437935  0.78972212  0.66293077  0.68456344  0.71845097  0.72751006]\n",
      "10 SVR\n",
      "[ 0.69847142  0.81679878  0.65669261  0.67448337  0.72189218  0.73891853]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy Mean</th>\n",
       "      <th>Test Accuracy Mean</th>\n",
       "      <th>Test Accuracy Std</th>\n",
       "      <th>Comsumed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.997988</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>0.000707654</td>\n",
       "      <td>0.0013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>{'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...</td>\n",
       "      <td>0.997271</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.00148045</td>\n",
       "      <td>0.00163766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'criterion': 'friedman_mse', 'i...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.0205482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'mse', 'max_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992566</td>\n",
       "      <td>0.00251902</td>\n",
       "      <td>0.0101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'mse', 'max_d...</td>\n",
       "      <td>0.99829</td>\n",
       "      <td>0.99173</td>\n",
       "      <td>0.00315819</td>\n",
       "      <td>0.0130576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.996789</td>\n",
       "      <td>0.99062</td>\n",
       "      <td>0.00273182</td>\n",
       "      <td>0.0582381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.989878</td>\n",
       "      <td>0.00146461</td>\n",
       "      <td>0.0108099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.98881</td>\n",
       "      <td>0.00469453</td>\n",
       "      <td>0.0958461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': None, 'max_f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985631</td>\n",
       "      <td>0.000755845</td>\n",
       "      <td>0.000833829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "      <td>0.750118</td>\n",
       "      <td>0.717876</td>\n",
       "      <td>0.0520376</td>\n",
       "      <td>0.000946283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "      <td>0.747603</td>\n",
       "      <td>0.712926</td>\n",
       "      <td>0.0403914</td>\n",
       "      <td>0.000806729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  \\\n",
       "0            LinearRegression   \n",
       "8                   LinearSVR   \n",
       "2   GradientBoostingRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7       RandomForestRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5            BaggingRegressor   \n",
       "3                MLPRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "10                        SVR   \n",
       "9                       NuSVR   \n",
       "\n",
       "                                           Parameters Train Accuracy Mean  \\\n",
       "0   {'copy_X': True, 'fit_intercept': True, 'n_job...            0.997988   \n",
       "8   {'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...            0.997271   \n",
       "2   {'alpha': 0.9, 'criterion': 'friedman_mse', 'i...            0.999945   \n",
       "6   {'bootstrap': False, 'criterion': 'mse', 'max_...                   1   \n",
       "7   {'bootstrap': True, 'criterion': 'mse', 'max_d...             0.99829   \n",
       "4   {'base_estimator': None, 'learning_rate': 1.0,...            0.996789   \n",
       "5   {'base_estimator': None, 'bootstrap': True, 'b...            0.997998   \n",
       "3   {'activation': 'relu', 'alpha': 0.0001, 'batch...            0.999974   \n",
       "1   {'criterion': 'mse', 'max_depth': None, 'max_f...                   1   \n",
       "10  {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...            0.750118   \n",
       "9   {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...            0.747603   \n",
       "\n",
       "   Test Accuracy Mean Test Accuracy Std Comsumed Time  \n",
       "0            0.996853       0.000707654     0.0013028  \n",
       "8            0.996044        0.00148045    0.00163766  \n",
       "2              0.9934          0.002396     0.0205482  \n",
       "6            0.992566        0.00251902     0.0101262  \n",
       "7             0.99173        0.00315819     0.0130576  \n",
       "4             0.99062        0.00273182     0.0582381  \n",
       "5            0.989878        0.00146461     0.0108099  \n",
       "3             0.98881        0.00469453     0.0958461  \n",
       "1            0.985631       0.000755845   0.000833829  \n",
       "10           0.717876         0.0520376   0.000946283  \n",
       "9            0.712926         0.0403914   0.000806729  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "estimator_list = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    MLPRegressor(solver='lbfgs'),\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    LinearSVR(),\n",
    "    NuSVR(),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits=6, train_size=0.7, test_size=0.2, random_state=168)\n",
    "df_columns = ['Name', 'Parameters', 'Train Accuracy Mean', 'Test Accuracy Mean', 'Test Accuracy Std', 'Comsumed Time']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "row_index = 0\n",
    "for estimator in estimator_list:\n",
    "    df.loc[row_index, 'Name'] = estimator.__class__.__name__\n",
    "    df.loc[row_index, 'Parameters'] = str(estimator.get_params())\n",
    "    cv_results = cross_validate(estimator, X, y, cv=cv_split)\n",
    "    df.loc[row_index, 'Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    df.loc[row_index, 'Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "    df.loc[row_index, 'Test Accuracy Std'] = cv_results['test_score'].std()\n",
    "    df.loc[row_index, 'Comsumed Time'] = cv_results['fit_time'].mean()\n",
    "    print(row_index, estimator.__class__.__name__)\n",
    "    print(cv_results['test_score'])\n",
    "    row_index += 1\n",
    "df = df.sort_values(by='Test Accuracy Mean', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LinearRegression\n",
      "[ 0.99668695  0.99740428  0.99626232  0.99815366  0.99643967  0.99617352]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jeremy/miniconda3/envs/test/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 DecisionTreeRegressor\n",
      "[ 0.98594214  0.98101728  0.9902498   0.99214139  0.98825265  0.98640099]\n",
      "2 GradientBoostingRegressor\n",
      "[ 0.9893405   0.9956214   0.99208629  0.99678845  0.99410616  0.992862  ]\n",
      "3 MLPRegressor\n",
      "[ 0.98584838  0.99207488  0.98311643  0.99324244  0.99516034  0.98193013]\n",
      "4 AdaBoostRegressor\n",
      "[ 0.98655749  0.9940986   0.98762657  0.99372077  0.99273573  0.98829349]\n",
      "5 BaggingRegressor\n",
      "[ 0.98885764  0.99604473  0.990598    0.99283665  0.98615304  0.98840329]\n",
      "6 ExtraTreesRegressor\n",
      "[ 0.99099864  0.99416029  0.97831163  0.99361489  0.99170231  0.9925396 ]\n",
      "7 RandomForestRegressor\n",
      "[ 0.98643016  0.98974167  0.98650209  0.99428823  0.98867631  0.98865193]\n",
      "8 LinearSVR\n",
      "[ 0.99620115  0.99796397  0.99531107  0.99785476  0.99495417  0.9939391 ]\n",
      "9 NuSVR\n",
      "[ 0.69437935  0.78972212  0.66293077  0.68456344  0.71845097  0.72751006]\n",
      "10 SVR\n",
      "[ 0.69847142  0.81679878  0.65669261  0.67448337  0.72189218  0.73891853]\n",
      "11 XGBRegressor\n",
      "[ 0.99218267  0.99571955  0.99415783  0.9975977   0.9955749   0.99305473]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy Mean</th>\n",
       "      <th>Test Accuracy Mean</th>\n",
       "      <th>Test Accuracy Std</th>\n",
       "      <th>Comsumed Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.997988</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>0.000707654</td>\n",
       "      <td>0.000729521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>{'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...</td>\n",
       "      <td>0.997271</td>\n",
       "      <td>0.996037</td>\n",
       "      <td>0.00148015</td>\n",
       "      <td>0.00174077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'base_score': 0.5, 'colsample_bylevel': 1, 'c...</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.994715</td>\n",
       "      <td>0.00180454</td>\n",
       "      <td>0.0108908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'criterion': 'friedman_mse', 'i...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.993467</td>\n",
       "      <td>0.00242839</td>\n",
       "      <td>0.0252855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.990505</td>\n",
       "      <td>0.00308194</td>\n",
       "      <td>0.0666904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.990482</td>\n",
       "      <td>0.00321976</td>\n",
       "      <td>0.0197992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'mse', 'max_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>0.00543207</td>\n",
       "      <td>0.0134823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'mse', 'max_d...</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.989048</td>\n",
       "      <td>0.00263221</td>\n",
       "      <td>0.0228015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.988562</td>\n",
       "      <td>0.00514433</td>\n",
       "      <td>0.0979211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': None, 'max_f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987334</td>\n",
       "      <td>0.00353943</td>\n",
       "      <td>0.00110428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "      <td>0.750118</td>\n",
       "      <td>0.717876</td>\n",
       "      <td>0.0520376</td>\n",
       "      <td>0.0012542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "      <td>0.747603</td>\n",
       "      <td>0.712926</td>\n",
       "      <td>0.0403914</td>\n",
       "      <td>0.00111723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  \\\n",
       "0            LinearRegression   \n",
       "8                   LinearSVR   \n",
       "11               XGBRegressor   \n",
       "2   GradientBoostingRegressor   \n",
       "4           AdaBoostRegressor   \n",
       "5            BaggingRegressor   \n",
       "6         ExtraTreesRegressor   \n",
       "7       RandomForestRegressor   \n",
       "3                MLPRegressor   \n",
       "1       DecisionTreeRegressor   \n",
       "10                        SVR   \n",
       "9                       NuSVR   \n",
       "\n",
       "                                           Parameters Train Accuracy Mean  \\\n",
       "0   {'copy_X': True, 'fit_intercept': True, 'n_job...            0.997988   \n",
       "8   {'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...            0.997271   \n",
       "11  {'base_score': 0.5, 'colsample_bylevel': 1, 'c...            0.999822   \n",
       "2   {'alpha': 0.9, 'criterion': 'friedman_mse', 'i...            0.999945   \n",
       "4   {'base_estimator': None, 'learning_rate': 1.0,...            0.996141   \n",
       "5   {'base_estimator': None, 'bootstrap': True, 'b...            0.998444   \n",
       "6   {'bootstrap': False, 'criterion': 'mse', 'max_...                   1   \n",
       "7   {'bootstrap': True, 'criterion': 'mse', 'max_d...            0.998387   \n",
       "3   {'activation': 'relu', 'alpha': 0.0001, 'batch...            0.999976   \n",
       "1   {'criterion': 'mse', 'max_depth': None, 'max_f...                   1   \n",
       "10  {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...            0.750118   \n",
       "9   {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...            0.747603   \n",
       "\n",
       "   Test Accuracy Mean Test Accuracy Std Comsumed Time  \n",
       "0            0.996853       0.000707654   0.000729521  \n",
       "8            0.996037        0.00148015    0.00174077  \n",
       "11           0.994715        0.00180454     0.0108908  \n",
       "2            0.993467        0.00242839     0.0252855  \n",
       "4            0.990505        0.00308194     0.0666904  \n",
       "5            0.990482        0.00321976     0.0197992  \n",
       "6            0.990221        0.00543207     0.0134823  \n",
       "7            0.989048        0.00263221     0.0228015  \n",
       "3            0.988562        0.00514433     0.0979211  \n",
       "1            0.987334        0.00353943    0.00110428  \n",
       "10           0.717876         0.0520376     0.0012542  \n",
       "9            0.712926         0.0403914    0.00111723  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "estimator_list = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    MLPRegressor(solver='lbfgs'),\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    LinearSVR(),\n",
    "    NuSVR(),\n",
    "    SVR(),\n",
    "    XGBRegressor()\n",
    "]\n",
    "\n",
    "cv_split = ShuffleSplit(n_splits=6, train_size=0.7, test_size=0.2, random_state=168)\n",
    "df_columns = ['Name', 'Parameters', 'Train Accuracy Mean', 'Test Accuracy Mean', 'Test Accuracy Std', 'Comsumed Time']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "row_index = 0\n",
    "for estimator in estimator_list:\n",
    "    df.loc[row_index, 'Name'] = estimator.__class__.__name__\n",
    "    df.loc[row_index, 'Parameters'] = str(estimator.get_params())\n",
    "    cv_results = cross_validate(estimator, X, y, cv=cv_split)\n",
    "    df.loc[row_index, 'Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    df.loc[row_index, 'Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "    df.loc[row_index, 'Test Accuracy Std'] = cv_results['test_score'].std()\n",
    "    df.loc[row_index, 'Comsumed Time'] = cv_results['fit_time'].mean()\n",
    "    print(row_index, estimator.__class__.__name__)\n",
    "    print(cv_results['test_score'])\n",
    "    row_index += 1\n",
    "df = df.sort_values(by='Test Accuracy Mean', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搜索模型最优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV process use 13.11 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "xgb_model = XGBRegressor(nthread = 2)\n",
    "cv_split = ShuffleSplit(n_splits=6, train_size=0.7, test_size=0.2)\n",
    "param_grid = dict(\n",
    "    max_depth = [4, 5, 6, 7],\n",
    "    learning_rate = np.linspace(0.03, 0.3, 10),\n",
    "    n_estimators = [100, 200]\n",
    ")\n",
    "start = time.time()\n",
    "grid = GridSearchCV(xgb_model, param_grid, cv=cv_split, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "print('GridSearchCV process use %.2f seconds'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.089999999999999997, 'max_depth': 5, 'n_estimators': 200}\n",
      "-0.707639251894\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(len(grid._get_param_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
